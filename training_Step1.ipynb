{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fca01d7-6b89-4a21-ab89-969716286150",
   "metadata": {},
   "source": [
    "# Training Phase\n",
    "This code trains the model. It:\n",
    "\n",
    "* Uses transfer learning on ResNet50.\n",
    "\n",
    "* Only fine-tunes the final fully connected layer (you can change this if you want to fine-tune the entire model).\n",
    "\n",
    "* Tracks training/validation loss and accuracy.\n",
    "\n",
    "* Saves the best model based on validation loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3fb91d1-fdd8-4d4e-85ba-9353db3e9c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fredrick-gacheru/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/fredrick-gacheru/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10]\n",
      "Train Loss: 0.0636, Accuracy: 0.9769\n",
      "Val Loss: 0.0038, Accuracy: 0.9989\n",
      "âœ… Best model saved.\n",
      "\n",
      "Epoch [2/10]\n",
      "Train Loss: 0.0260, Accuracy: 0.9919\n",
      "Val Loss: 0.0063, Accuracy: 0.9983\n",
      "\n",
      "Epoch [3/10]\n",
      "Train Loss: 0.0249, Accuracy: 0.9919\n",
      "Val Loss: 0.0055, Accuracy: 0.9983\n",
      "\n",
      "Epoch [4/10]\n",
      "Train Loss: 0.0196, Accuracy: 0.9940\n",
      "Val Loss: 0.0027, Accuracy: 0.9994\n",
      "âœ… Best model saved.\n",
      "\n",
      "Epoch [5/10]\n",
      "Train Loss: 0.0161, Accuracy: 0.9949\n",
      "Val Loss: 0.0035, Accuracy: 0.9994\n",
      "\n",
      "Epoch [6/10]\n",
      "Train Loss: 0.0083, Accuracy: 0.9972\n",
      "Val Loss: 0.0034, Accuracy: 0.9994\n",
      "\n",
      "Epoch [7/10]\n",
      "Train Loss: 0.0069, Accuracy: 0.9979\n",
      "Val Loss: 0.0058, Accuracy: 0.9989\n",
      "\n",
      "Epoch [8/10]\n",
      "Train Loss: 0.0045, Accuracy: 0.9984\n",
      "Val Loss: 0.0060, Accuracy: 0.9989\n",
      "\n",
      "Epoch [9/10]\n",
      "Train Loss: 0.0035, Accuracy: 0.9992\n",
      "Val Loss: 0.0082, Accuracy: 0.9989\n",
      "\n",
      "Epoch [10/10]\n",
      "Train Loss: 0.0023, Accuracy: 0.9991\n",
      "Val Loss: 0.0067, Accuracy: 0.9989\n",
      "\n",
      "ðŸŽ‰ Training complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Updated ResNet normalization values\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# Directories\n",
    "data_dir = 'cleaned_and_ready_for_use_data'\n",
    "train_dir = f\"{data_dir}/train\"\n",
    "val_dir = f\"{data_dir}/val\"\n",
    "test_dir = f\"{data_dir}/test\"\n",
    "\n",
    "# Datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=val_test_transforms)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=val_test_transforms)\n",
    "\n",
    "# Loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load pre-trained ResNet50\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# âœ… Unfreeze last few layers\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Replace final layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0005)\n",
    "\n",
    "# Optional learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "\n",
    "# Training\n",
    "epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, correct_val, total_val = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = correct_val / total_val\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # Adjust LR\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch+1}/{epochs}]\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        best_val_loss = val_loss\n",
    "        print(\"âœ… Best model saved.\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Training complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55879cd-a043-4b88-8397-f783a4cc898b",
   "metadata": {},
   "source": [
    "# Testing the model\n",
    "I am testing the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "618cdcb3-b226-49f2-9096-13c2fa7def7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fredrick-gacheru/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/fredrick-gacheru/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       1.00      1.00      1.00       115\n",
      "         dog       1.00      1.00      1.00       329\n",
      "       human       1.00      1.00      1.00      1324\n",
      "\n",
      "    accuracy                           1.00      1768\n",
      "   macro avg       1.00      1.00      1.00      1768\n",
      "weighted avg       1.00      1.00      1.00      1768\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 115    0    0]\n",
      " [   0  329    0]\n",
      " [   0    0 1324]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Normalization values (same as training)\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Test transform\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# Dataset & Loader\n",
    "data_dir = 'cleaned_and_ready_for_use_data'\n",
    "test_dir = f\"{data_dir}/test\"\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=val_test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Recreate model architecture\n",
    "model = models.resnet50(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)  # Must match training\n",
    "model = model.to(device)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Evaluation\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=test_dataset.classes))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c24c601-8d44-41b6-9673-68919e98e191",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "The test results are slightly worrying because they seem to imply that the model had access to the test data in the training phase. I will use different images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01380dd0-941a-4e81-b9c9-e09a988f0439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/fredrick-gacheru/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2025-5-12 Python-3.12.7 torch-2.7.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "[W728 01:27:22.173915654 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.175689076 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.176180582 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.176574982 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.177532447 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.177996188 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.178437537 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.178985341 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.179845855 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.180673393 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.182770932 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.183641181 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.184933727 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.185527163 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.186047783 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.187961948 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.189749233 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.190476144 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.191697542 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.192191615 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.192903429 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.193237988 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.194389705 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.194782437 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.195242716 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.196139129 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.196519788 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.196828445 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.197635302 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.197981551 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.198553028 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.199352114 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.199846185 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.200431893 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.200893361 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.201259231 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.202108858 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.202526192 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.202930171 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.203471097 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.203776201 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.204056571 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.204586269 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.204870779 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.205172866 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.205814306 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.206162102 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.206433458 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.207251352 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.207584463 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.207973045 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.208578750 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.208923825 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.209208691 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.209974900 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.210339726 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.210716788 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.211529789 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:22.212295877 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "\n",
    "# Load YOLOv5 model only once (outside the function)\n",
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "yolo_model.conf = 0.5  # Confidence threshold\n",
    "LABEL_MAP = {'cat': 15, 'dog': 16, 'human': 0}  # COCO labels\n",
    "\n",
    "def preprocess_with_yolo(image_path, resize=(224, 224)):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"âŒ Failed to load image: {image_path}\")\n",
    "    \n",
    "    results = yolo_model(image)\n",
    "    detections = results.xyxy[0]\n",
    "\n",
    "    for *box, conf, cls in detections:\n",
    "        if int(cls) in LABEL_MAP.values():\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            cropped = image[y1:y2, x1:x2]\n",
    "            resized = cv2.resize(cropped, resize)\n",
    "            return Image.fromarray(cv2.cvtColor(resized, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for PIL\n",
    "\n",
    "    print(f\"âš ï¸ No cat or dog confidently detected in: {image_path}\")\n",
    "    return None\n",
    "\n",
    "def predict_image(image_path, model_path, class_names):\n",
    "    # Define the transform (must be before using it!)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "\n",
    "    # Preprocess with YOLOv5\n",
    "    preprocessed_image = preprocess_with_yolo(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"something else\"\n",
    "\n",
    "    # Apply transform to preprocessed PIL image\n",
    "    image_tensor = transform(preprocessed_image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Load model\n",
    "    model = models.resnet50(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 4)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probs = torch.nn.functional.softmax(outputs[0], dim=0)\n",
    "        top_prob, top_class = torch.max(probs, 0)\n",
    "\n",
    "    # Print probabilities\n",
    "    print(f\"\\nPrediction results for: {image_path}\")\n",
    "    for i, prob in enumerate(probs):\n",
    "        label = class_names[i] if i < len(class_names) else \"something else\"\n",
    "        print(f\"{label}: {prob.item()*100:.2f}%\")\n",
    "\n",
    "    predicted_label = class_names[top_class.item()] if top_class.item() < len(class_names) else \"something else\"\n",
    "    return predicted_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6c6a293-b8df-4fcf-b45d-b9ee14654ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fredrick-gacheru/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:907: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction results for: demo_images/human_1.jpg\n",
      "cat: 38.01%\n",
      "dog: 61.77%\n",
      "human: 0.17%\n",
      "something else: 0.05%\n",
      "Predicted label: dog\n"
     ]
    }
   ],
   "source": [
    "class_names = ['cat', 'dog', 'human', 'something else']\n",
    "label = predict_image(\"demo_images/human_1.jpg\", \"best_model.pth\", class_names)\n",
    "print(f\"Predicted label: {label}\")\n",
    "\n",
    "# for i in range(1, 6):\n",
    "#     print(f\"\\n--- Predicting dog_{i}.jpg ---\")\n",
    "#     predict_image(f\"demo_images/dog_{i}.jpg\", model, val_test_transforms, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a66af25-49c8-4ad5-bf2d-4ce8e3261d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/fredrick-gacheru/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2025-5-12 Python-3.12.7 torch-2.7.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "[W728 01:27:50.991971339 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.993580376 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.994074535 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.994453575 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.995394608 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.995868798 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.996298958 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.997122594 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.998251109 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.000176455 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.001330711 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.001935425 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.002825622 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.003283023 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.003920869 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.007634106 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.008398310 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.008905340 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.009715449 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.010245685 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.011176239 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.011774281 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.012997707 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.013525499 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.013973203 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.014864008 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.015342220 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.015670246 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.016514494 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.016873452 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.017284037 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.018089385 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.018605041 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.019241619 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.019700883 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.020023966 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.020861930 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.021324061 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.021817156 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.022412866 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.022751793 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.023047552 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.023621228 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.023931262 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.024253137 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.024908733 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.025311578 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.025617594 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.026889334 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.027398604 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.028054641 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.028808598 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.029244369 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.029708995 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.030652288 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.031080160 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.031497386 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.032297602 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W728 01:27:50.033129414 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "/home/fredrick-gacheru/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:907: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: dog\n",
      "Probabilities per class:\n",
      "  cat: 38.0%\n",
      "  dog: 61.8%\n",
      "  human: 0.2%\n",
      "  something else: 0.1%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Load YOLO model once\n",
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "yolo_model.conf = 0.5\n",
    "LABEL_MAP = {'cat': 15, 'dog': 16, 'human': 0}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------- Functions ----------\n",
    "\n",
    "def preprocess_with_yolo(image_path, resize=(224, 224)):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"âŒ Failed to load image: {image_path}\")\n",
    "\n",
    "    results = yolo_model(image)\n",
    "    detections = results.xyxy[0]\n",
    "\n",
    "    for *box, conf, cls in detections:\n",
    "        if int(cls) in LABEL_MAP.values():\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            cropped = image[y1:y2, x1:x2]\n",
    "            resized = cv2.resize(cropped, resize)\n",
    "            return Image.fromarray(cv2.cvtColor(resized, cv2.COLOR_BGR2RGB))\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_model(model_path, num_classes=4):\n",
    "    model = models.resnet50(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_image(image_path, model, class_names):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "\n",
    "    preprocessed_image = preprocess_with_yolo(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"something else\", None\n",
    "\n",
    "    image_tensor = transform(preprocessed_image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probs = torch.nn.functional.softmax(outputs[0], dim=0)\n",
    "        top_prob, top_class = torch.max(probs, 0)\n",
    "\n",
    "    predicted_label = class_names[top_class.item()]\n",
    "    return predicted_label, probs.cpu().numpy()\n",
    "\n",
    "\n",
    "# ---------- Main (for testing only) ----------\n",
    "if __name__ == \"__main__\":\n",
    "    model = load_model(\"best_model.pth\", num_classes=4)\n",
    "    class_names = ['cat', 'dog', 'human', 'something else']\n",
    "    label, probs = predict_image(\"demo_images/human_1.jpg\", model, class_names)\n",
    "    print(f\"Predicted: {label}\")\n",
    "    if probs is not None:\n",
    "        print(\"Probabilities per class:\")\n",
    "        for cls_name, p in zip(class_names, probs):\n",
    "            print(f\"  {cls_name}: {p * 100:.1f}%\")  # formatted as percentage\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
