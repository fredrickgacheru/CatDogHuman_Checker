{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b851b3-a0ab-4f41-a3cc-db52ef397227",
   "metadata": {},
   "source": [
    "## Process\n",
    "This code splits the dataset into training, validate, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129d3936-1537-4ec0-b5a5-9413a40a3577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset successfully split into train, val, and test folders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Define source folders\n",
    "source_folders = {\n",
    "    \"cat\": \"cropped_images/cat_images\",\n",
    "    \"dog\": \"cropped_images/dog_images\",\n",
    "    \"human\": \"human_images\"\n",
    "}\n",
    "\n",
    "# Define target base folder\n",
    "target_base = \"dataset\"\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "split_ratios = [0.8, 0.1, 0.1]\n",
    "\n",
    "# Create directory structure\n",
    "for split in splits:\n",
    "    for label in source_folders.keys():\n",
    "        Path(f\"{target_base}/{split}/{label}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process each class folder\n",
    "for label, folder in source_folders.items():\n",
    "    images = os.listdir(folder)\n",
    "    random.shuffle(images)\n",
    "\n",
    "    total = len(images)\n",
    "    train_end = int(split_ratios[0] * total)\n",
    "    val_end = train_end + int(split_ratios[1] * total)\n",
    "\n",
    "    split_data = {\n",
    "        \"train\": images[:train_end],\n",
    "        \"val\": images[train_end:val_end],\n",
    "        \"test\": images[val_end:]\n",
    "    }\n",
    "\n",
    "    for split, files in split_data.items():\n",
    "        for file in files:\n",
    "            src = os.path.join(folder, file)\n",
    "            dst = os.path.join(target_base, split, label, file)\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "print(\"âœ… Dataset successfully split into train, val, and test folders.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360e6772-d962-4561-bcbf-14a619bac0a6",
   "metadata": {},
   "source": [
    "# Dealing with Human Images\n",
    "This code picks 2500 random human images which can be used in training. The images that were there were too many and could have biased the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59b6f8f5-563b-474f-a78b-708b05ce4c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Copied 2500 human images to working_dataset/balanced_train/_human\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "original_human_path = 'dataset/train/human'\n",
    "output_path = 'working_dataset/balanced_train/_human'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Number of human images to retain\n",
    "target_human_count = 2500\n",
    "\n",
    "# Get list of human image files\n",
    "human_images = [f for f in os.listdir(original_human_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Randomly select 2500 images\n",
    "selected_images = random.sample(human_images, target_human_count)\n",
    "\n",
    "# Copy selected images to new folder\n",
    "for fname in selected_images:\n",
    "    src = os.path.join(original_human_path, fname)\n",
    "    dst = os.path.join(output_path, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "print(f\"âœ… Copied {len(selected_images)} human images to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34157b3c-0b73-4a1f-9c7c-fe29b5ff4f2d",
   "metadata": {},
   "source": [
    "# Augment the images\n",
    "This code augments an imbalanced dataset to ensure each class (cat, dog, human) reaches a specific number of images. It first copies the original images to a new output directory and then generates additional augmented images using random transformations until the desired count per class is met. This helps balance the dataset, improving model fairness and performance across classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07266921-bd66-4651-b4bf-0a0a2b13a3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Augmenting CAT... (911 â†’ 3000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2089/2089 [01:03<00:00, 32.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Augmenting DOG... (2625 â†’ 3000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:13<00:00, 27.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Augmenting HUMAN... (2500 â†’ 3000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:12<00:00, 40.13it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_path = 'working_dataset/balanced_train'\n",
    "output_path = 'augmented_dataset_balanced'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "target_counts = {\n",
    "    'cat': 3000,\n",
    "    'dog': 3000,\n",
    "    'human': 3000\n",
    "}\n",
    "\n",
    "def get_transform(class_name):\n",
    "    if class_name == 'cat':\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(degrees=(0, 270)),  # Covers 90Â°, 180Â°, 270Â°\n",
    "            transforms.ColorJitter(\n",
    "                brightness=random.uniform(0.3, 0.8),\n",
    "                contrast=random.uniform(0.3, 0.8),\n",
    "                saturation=random.uniform(0.3, 0.8)\n",
    "            ),\n",
    "            transforms.RandomAffine(degrees=30, translate=(0.1, 0.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=random.uniform(0.2, 0.4),\n",
    "                contrast=random.uniform(0.2, 0.4)\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "        ])\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "for class_name in target_counts:\n",
    "    src_folder = os.path.join(input_path, class_name)\n",
    "    dst_folder = os.path.join(output_path, class_name)\n",
    "    os.makedirs(dst_folder, exist_ok=True)\n",
    "\n",
    "    image_files = [f for f in os.listdir(src_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    for fname in image_files:\n",
    "        Image.open(os.path.join(src_folder, fname)).save(os.path.join(dst_folder, fname))\n",
    "\n",
    "    current_count = len(image_files)\n",
    "    needed = target_counts[class_name] - current_count\n",
    "\n",
    "    print(f\"\\nðŸ”„ Augmenting {class_name.upper()}... ({current_count} â†’ {target_counts[class_name]})\")\n",
    "\n",
    "    transform = get_transform(class_name)\n",
    "\n",
    "    for i in tqdm(range(needed)):\n",
    "        img_name = random.choice(image_files)\n",
    "        img_path = os.path.join(src_folder, img_name)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            transformed_tensor = transform(image)\n",
    "            transformed_image = to_pil(transformed_tensor)\n",
    "            new_name = f\"{os.path.splitext(img_name)[0]}_aug{i}.jpg\"\n",
    "            transformed_image.save(os.path.join(dst_folder, new_name))\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error processing {img_name}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f38de025-a667-450f-b7c6-bf35898509a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Train: 9000\n",
      "Val:   1764\n",
      "Test:  1768\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Define transforms again if needed\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Set new base path (update as necessary)\n",
    "base_path = 'cleaned_and_ready_for_use_data' \n",
    "\n",
    "# Recreate datasets\n",
    "train_dataset = ImageFolder(root=os.path.join(base_path, 'train'), transform=transform)\n",
    "val_dataset = ImageFolder(root=os.path.join(base_path, 'val'), transform=transform)\n",
    "test_dataset = ImageFolder(root=os.path.join(base_path, 'test'), transform=transform)\n",
    "\n",
    "# Recreate data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}\")\n",
    "print(f\"Val:   {len(val_dataset)}\")\n",
    "print(f\"Test:  {len(test_dataset)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
